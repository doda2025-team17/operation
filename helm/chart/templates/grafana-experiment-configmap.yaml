{{- if and .Values.monitoring.enabled (index .Values "kube-prometheus-stack" "grafana" "enabled") }}
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-experiment-dashboard
  namespace: {{ .Values.namespace.name }}
  labels:
    grafana_dashboard: sms-app
  annotations:
    grafana_folder: "SMS App"
data: # THIS IS ONLY AN EXAMPLE, WE SHOULD CUSTOMIZE IT BASED ON OUR EXPERIMENT METRICS in A4
  sms-app-experiment.json: |-
    {
        "title": "Shadow vs Stable (Model Service)",
        "panels": [
            {
            "title": "Request Rate Comparison (v1 vs v2)",
            "type": "timeseries",
            "gridPos": { "h": 8, "w": 24, "x": 0, "y": 0 },
            "datasource": { "type": "prometheus", "uid": "${datasource}" },
            "fieldConfig": {
                "defaults": {
                "color": { "mode": "palette-classic" },
                "unit": "reqpm"
                }
            },
            "targets": [
                {
                "expr": "sum by (version) (rate(sms_model_predictions_total{namespace=\"{{ .Values.namespace.name }}\"}[5m])) * 60",
                "legendFormat": "v{{`{{version}}`}}",
                "refId": "A"
                }
            ]
            },
            {
            "title": "Inflight Requests",
            "type": "stat",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 8 },
            "datasource": { "type": "prometheus", "uid": "${datasource}" },
            "fieldConfig": {
                "defaults": {
                "color": { "mode": "palette-classic" },
                "unit": "short"
                }
            },
            "targets": [
                {
                "expr": "sum by (version) (sms_model_inflight_requests{namespace=\"{{ .Values.namespace.name }}\"})",
                "legendFormat": "v{{`{{version}}`}} inflight",
                "refId": "A"
                }
            ]
            },
            {
            "title": "Response Time p95 (s)",
            "type": "bargauge",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 8 },
            "datasource": { "type": "prometheus", "uid": "${datasource}" },
            "fieldConfig": {
                "defaults": {
                "color": { "mode": "thresholds" },
                "thresholds": {
                    "mode": "absolute",
                    "steps": [
                    { "color": "green", "value": null },
                    { "color": "yellow", "value": 0.5 },
                    { "color": "red", "value": 1 }
                    ]
                },
                "unit": "s",
                "min": 0,
                "max": 2
                }
            },
            "targets": [
                {
                "expr": "histogram_quantile(0.95, sum(rate(model_request_latency_seconds_bucket{namespace=\"{{ .Values.namespace.name }}\", version=\"v1\"}[5m])) by (le))",
                "legendFormat": "Stable p95",
                "refId": "A"
                },
                {
                "expr": "histogram_quantile(0.95, sum(rate(model_request_latency_seconds_bucket{namespace=\"{{ .Values.namespace.name }}\", version=\"v2\"}[5m])) by (le))",
                "legendFormat": "Canary p95",
                "refId": "B"
                }
            ]
            },
        {
            "title": "Model Inference Latency Comparison",
            "type": "timeseries",
            "gridPos": { "h": 8, "w": 24, "x": 0, "y": 16 },
            "datasource": { "type": "prometheus", "uid": "${datasource}" },
            "fieldConfig": {
                "defaults": {
                "color": { "mode": "palette-classic" },
                "unit": "s"
                }
            },
            "targets": [
                {
                "expr": "histogram_quantile(0.95, sum(rate(model_inference_seconds_bucket{namespace=\"{{ .Values.namespace.name }}\", version=\"v1\"}[5m])) by (le))",
                "legendFormat": "Stable Model p95",
                "refId": "A"
                },
                {
                "expr": "histogram_quantile(0.95, sum(rate(model_inference_seconds_bucket{namespace=\"{{ .Values.namespace.name }}\", version=\"v2\"}[5m])) by (le))",
                "legendFormat": "Canary Model p95",
                "refId": "B"
                }
            ]
            },
            {
            "title": "Avg Inference Time (s)",
            "type": "timeseries",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 24 },
            "datasource": { "type": "prometheus", "uid": "${datasource}" },
            "fieldConfig": {
                "defaults": {
                "color": { "mode": "palette-classic" },
                "unit": "s"
                }
            },
            "targets": [
                {
                "expr": "sum by (version) (rate(sms_model_inference_seconds_sum{namespace=\"{{ .Values.namespace.name }}\"}[$__rate_interval])) / sum by (version) (rate(sms_model_predictions_total{namespace=\"{{ .Values.namespace.name }}\"}[$__rate_interval]))",
                "legendFormat": "v{{`{{version}}`}} avg",
                "refId": "A"
                }
            ]
            },
            {
            "title": "Inference Count (per min)",
            "type": "timeseries",
            "gridPos": { "h": 8, "w": 12, "x": 12, "y": 24 },
            "datasource": { "type": "prometheus", "uid": "${datasource}" },
            "fieldConfig": {
                "defaults": {
                "color": { "mode": "palette-classic" },
                "unit": "reqpm"
                }
            },
            "targets": [
                {
                "expr": "sum by (version) (rate(sms_model_inference_seconds_count{namespace=\"{{ .Values.namespace.name }}\"}[$__rate_interval])) * 60",
                "legendFormat": "v{{`{{version}}`}} inferences",
                "refId": "A"
                }
            ]
            },
            {
            "title": "Predictions Created (per min)",
            "type": "timeseries",
            "gridPos": { "h": 8, "w": 12, "x": 0, "y": 32 },
            "datasource": { "type": "prometheus", "uid": "${datasource}" },
            "fieldConfig": {
                "defaults": {
                "color": { "mode": "palette-classic" },
                "unit": "reqpm"
                }
            },
            "targets": [
                {
                "expr": "sum by (version) (rate(sms_model_predictions_created{namespace=\"{{ .Values.namespace.name }}\"}[$__rate_interval])) * 60",
                "legendFormat": "v{{`{{version}}`}} created",
                "refId": "A"
                }
            ]
            }
        ],
        "refresh": "5s",
        "schemaVersion": 38,
        "style": "dark",
        "tags": ["sms-app", "experiment", "canary"],
        "templating": {
            "list": [
            {
                "current": { "selected": false, "text": "Prometheus", "value": "prometheus" },
                "hide": 0,
                "includeAll": false,
                "name": "datasource",
                "options": [],
                "query": "prometheus",
                "refresh": 1,
                "type": "datasource"
            }
            ]
        },
        "time": { "from": "now-1h", "to": "now" },
        "timepicker": {},
        "timezone": "browser",
        "uid": "sms-app-experiment",
        "version": 1
    }
{{- end }}
